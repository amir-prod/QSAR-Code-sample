{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce87f5ae-43b2-4559-b4c6-ebc805a1da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from molToTensor import MoleculeDataset\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GINConv\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4afb7c7-87fa-4fea-b3f0-9d59a087c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('GPU available')\n",
    "else:\n",
    "    print('GPU not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4657f1d4-2d5b-4610-bead-35b208548f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert molecules to graphs \n",
    "dataset = MoleculeDataset(root=\"../data/\", filename=\"train_data.csv\")\n",
    "train_dataset = dataset[:int(len(dataset)*0.9)]\n",
    "val_dataset = dataset[int(len(dataset)*0.9):]\n",
    "\n",
    "test_dataset = MoleculeDataset(root=\"../data/\", filename=\"test_data.csv\", test=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cbbe22-46a9-4e32-8373-ab9bb488dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training set   = {len(train_dataset)} graphs')\n",
    "print(f'Validation set = {len(val_dataset)} graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dce8cfbe-7d2f-457b-885e-e4d7da333f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=64,\n",
    "shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64,\n",
    "shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64,\n",
    "shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16c388ad-cf0f-468f-b38e-870e9fdf3d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(model, loader):\n",
    "    '''\n",
    "    define your metrics here. r2 and loss are defined \n",
    "    '''\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    r2 = 0\n",
    "    \n",
    "    for data in loader:\n",
    "        # data.y = data.y.type(torch.LongTensor)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss += criterion(out, data.y) / len(loader)\n",
    "        r2 += r2_score(out, data.y) / len(loader)\n",
    "    return loss, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e741949c-df74-4d2e-a412-dd4d400e499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining GIN achitecture \n",
    "# Gin is Graph Isomorphism Network  \n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, dim_h):\n",
    "        super(GIN, self).__init__()\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(train_dataset.num_node_features,\n",
    "dim_h), BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h),\n",
    "ReLU()))\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h),\n",
    "BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h),\n",
    "ReLU()))\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h),\n",
    "BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h),\n",
    "ReLU()))\n",
    "        self.conv4 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h),\n",
    "BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h),\n",
    "ReLU()))\n",
    "        self.conv5 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h),\n",
    "BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h),\n",
    "ReLU()))\n",
    "\n",
    "        self.lin1 = Linear(dim_h*3, dim_h*3)\n",
    "        self.lin2 = Linear(dim_h*3, 1024)\n",
    "        self.lin3 = Linear(1024, 512)\n",
    "        self.lin4 = Linear(512, 128)\n",
    "        self.lin5 = Linear(128, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Node embeddings\n",
    "        h1 = self.conv1(x, edge_index)\n",
    "        h2 = self.conv2(h1, edge_index)\n",
    "        h3 = self.conv3(h2, edge_index)\n",
    "        h4 = self.conv4(h3, edge_index)\n",
    "        h5 = self.conv5(h4, edge_index)\n",
    "        # Graph-level readout\n",
    "        h1 = global_add_pool(h1, batch)\n",
    "        h2 = global_add_pool(h2, batch)\n",
    "        h3 = global_add_pool(h3, batch)\n",
    "        h4 = global_add_pool(h4, batch)\n",
    "        h5 = global_add_pool(h5, batch)\n",
    "        # Concatenate graph embeddings\n",
    "        h = torch.cat((h1, h2, h3), dim=1)\n",
    "        # Regressor \n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training) \n",
    "        h = self.lin2(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training) \n",
    "        h = self.lin3(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training) \n",
    "        h = self.lin4(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training)         \n",
    "        return self.lin5(h).view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b000f0f-1812-4ca1-9aa2-0997d47bfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, loader):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    r2 = 0\n",
    "    for data in loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss += criterion(out, data.y)\n",
    "        r2 += r2_score(out, data.y) \n",
    "    return loss, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dd10a39-07ea-422c-b2a8-9fd0ed950d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lambda(epoch):\n",
    "    base_lr = 0.1\n",
    "    factor = 5\n",
    "    # \n",
    "    return base_lr/(factor + epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d3c910f-3dd5-4750-aa8b-92333553c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular training loop with mini-batching for 150 epochs:\n",
    "def train(model, loader):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    lr = 0.1\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr=1e-1)\n",
    "    # SGD instead of adam \n",
    "    \n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', min_lr=1e-6)\n",
    "    epochs = 20\n",
    "    model.train()\n",
    "    for epoch in range(epochs+1):\n",
    "        total_loss = 0\n",
    "        r2 = 0\n",
    "        val_loss = 0\n",
    "        val_r2 = 0\n",
    "        # Train on batches\n",
    "        for data in loader:\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = criterion(out, data.y)\n",
    "            total_loss += loss / len(loader)\n",
    "            r2 += r2_score(out.detach().numpy(), data.y.detach().numpy()) / len(loader)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # Validation\n",
    "        val_loss, val_r2 = test(model, val_loader)\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        print(f\"lr after update {optimizer.param_groups[0]['lr']}\")\n",
    "        print(f'Epoch {epoch:>3} | Train Loss:'\n",
    "f'{total_loss:.2f} | Train r2: {r2:>5.2f} | Val'\n",
    "f'Loss: {val_loss:.2f} | Val r2: {val_r2:.2f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4384888f-0cab-4e28-8fc7-a4cf11b913fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gin = GIN(dim_h=128)\n",
    "gin = train(gin, train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
